import cv2
import mediapipe as mp
import imutils
import time
from math import sqrt,pow

def findHand(frame, handDetector, visualize=False):
    """ This function uses the mediapipe to detect a hand

    Args:
        frame: The image in which the hand should be detected
        handDetector: The mediapipe detector object
        visualize: boolean that turns on visualization and draws helping points / lines to understand whats happening

    Returns:
        An array with landmarks of the detected hand or None if nothing is detected and the label of the hand, containing the side of it
        Landmarks are indexed by:
        WRIST = 0
        THUMB_CMC = 1
        THUMB_MCP = 2
        THUMB_IP = 3
        THUMB_TIP = 4
        INDEX_FINGER_MCP = 5
        INDEX_FINGER_PIP = 6
        INDEX_FINGER_DIP = 7
        INDEX_FINGER_TIP = 8
        MIDDLE_FINGER_MCP = 9
        MIDDLE_FINGER_PIP = 10
        MIDDLE_FINGER_DIP = 11
        MIDDLE_FINGER_TIP = 12
        RING_FINGER_MCP = 13
        RING_FINGER_PIP = 14
        RING_FINGER_DIP = 15
        RING_FINGER_TIP = 16
        PINKY_MCP = 17
        PINKY_PIP = 18
        PINKY_DIP = 19
        PINKY_TIP = 20
    """
    global mpDraw
    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert input image to RGB
    results = handDetector.process(imgRGB) #run the image through the mediapipe detector
    
    if results.multi_hand_landmarks is not None:
        if visualize:
            mpDraw.draw_landmarks(frame,results.multi_hand_landmarks[0],mpHands.HAND_CONNECTIONS) #draw the hand connections onto the frame. NOTE: comment this out if it is unwanted
        return results.multi_hand_landmarks[0].landmark, results.multi_handedness[0].classification[0].label
    else:
        return None, ""

def ptDist(x1, y1, x2, y2):
    """Calculates the distance between points P1 and P2

    Args:
        x1:  P1 X
        y1:  P1 Y
        x2:  P2 X
        y2:  P2 Y

    Returns:
        The distance (as float)
    """
    return(sqrt(pow(x2 - x1, 2) + pow(y2 - y1, 2)))

def fingersClosed(frame, landmarks, visualize = False):
    """Determines if the fingers are closed in an image using its corresponding mediapipe hand landmarks

    Args:
        frame: The image to check
        landmarks: The hand landmarks generated by mediapipe
        visualize (bool, optional): If set to True, this function draws points/lines to understand whats happening. Defaults to False.

    Returns:
        True if fingers are closed, False otherwise
    """
    h, w = frame.shape[:2] #get the frame size
    mcpDist = ptDist(int(landmarks[5].x * w), int(landmarks[5].y * h), int(landmarks[17].x * w), int(landmarks[17].y * h)) #get the distance between the base of index and pinky finger
    tipDist = ptDist(int(landmarks[8].x * w), int(landmarks[8].y * h), int(landmarks[20].x * w), int(landmarks[20].y * h)) #get the distance between the tip of index and pinky finger
    threshold = mcpDist/3 #threshold in pixel to be able to control the detection 
    if visualize: #draw lines for the distances used. the longer one will be green
        if tipDist > mcpDist+threshold: 
            cv2.line(frame,(int(landmarks[5].x * w), int(landmarks[5].y * h)), (int(landmarks[17].x * w), int(landmarks[17].y * h)), (0,0,255), 2) 
            cv2.line(frame,(int(landmarks[8].x * w), int(landmarks[8].y * h)), (int(landmarks[20].x * w), int(landmarks[20].y * h)), (0,255,0), 2)
        else:
            cv2.line(frame,(int(landmarks[5].x * w), int(landmarks[5].y * h)), (int(landmarks[17].x * w), int(landmarks[17].y * h)), (0,255,0), 2)
            cv2.line(frame,(int(landmarks[8].x * w), int(landmarks[8].y * h)), (int(landmarks[20].x * w), int(landmarks[20].y * h)), (0,0,255), 2)
        #draw circles for the points used in the calculation
        cv2.circle(frame, (int(landmarks[5].x * w), int(landmarks[5].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[17].x * w), int(landmarks[17].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[8].x * w), int(landmarks[8].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[20].x * w), int(landmarks[20].y * h)), 2,(255,255,255),4)
    return not tipDist > mcpDist+threshold # if the distance of the tips is bigger than on the base, then the fingers are spread out, which means that they are not closed

def handUp(frame, landmarks, side):
    #thumb 4 pinky 20
    diff = landmarks[4].x - landmarks[20].x + landmarks[4].y - landmarks[20].y
    if diff > 0:
        if side.lower() == "right":
            return True
        elif side.lower() == "left":
            return False 
    elif diff < 0:
        if side.lower() == "right":
            return False
        elif side.lower() == "left":
            return True
    return False #default should never occurr but i dont want it to crash if it does

def curState(frame,landmarks, side, visualize = False):
    visualize = True
    state = "undefined"
    if landmarks is None:
        state = "NO HAND"
    elif fingersClosed(frame,landmarks, visualize):
        state = "STOP"
    elif handUp(frame,landmarks,side):
        state = "STAND UP"
    elif not handUp(frame,landmarks,side):
        state = "SIT DOWN"
    #TODO andere gesten auch erkennen
    return state

mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
if __name__ == "__main__":
    cam = cv2.VideoCapture(0) #set default video input as camera
    #initialize the detector in video mode, with a maximum of one hand
    handDetector =  mpHands.Hands(static_image_mode=True,
                          max_num_hands=1,
                          min_detection_confidence=0.5,
                          min_tracking_confidence=0.5)
    
    #variables for fps calculation
    pTime = 0
    cTime = 0
    
    while(True):
        (grabbed, frame) = cam.read() #get live image from camera
        frame = cv2.flip(frame, 1) #flip the image to get mirrored view
        h, w, c = frame.shape
        landmarks, side = findHand(frame, handDetector) #let mediapipe detect the hand
        
        cv2.putText(frame,curState(frame,landmarks,side,True), (10,140), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255), 3) #check if fingers are closed and write the result onto the wrist
        cv2.putText(frame,side, (10,210), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255), 3) #check if fingers are closed and write the result onto the wrist
        
        #calculate fps
        cTime = time.time()
        fps = 1/(cTime-pTime)
        pTime = cTime
        cv2.putText(frame,str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255), 3) #print fps on frame

        cv2.imshow("Video", frame) #display live feed
        #input()
        #exit()
        input = cv2.waitKey(1) & 0xFF #quit the program with q
        if input == ord("q"):
            break

    cam.release()
    cv2.destroyAllWindows()