import cv2
import mediapipe as mp
import imutils
import time
from math import sqrt,pow

def findHand(frame, handDetector, visualize=False):
    """ This function uses the mediapipe to detect a hand

    Args:
        frame: The image in which the hand should be detected
        handDetector: The mediapipe detector object
        visualize: boolean that turns on visualization and draws helping points / lines to understand whats happening

    Returns:
        An array with landmarks of the detected hand or None if nothing is detected.
        Landmarks are indexed by:
        WRIST = 0
        THUMB_CMC = 1
        THUMB_MCP = 2
        THUMB_IP = 3
        THUMB_TIP = 4
        INDEX_FINGER_MCP = 5
        INDEX_FINGER_PIP = 6
        INDEX_FINGER_DIP = 7
        INDEX_FINGER_TIP = 8
        MIDDLE_FINGER_MCP = 9
        MIDDLE_FINGER_PIP = 10
        MIDDLE_FINGER_DIP = 11
        MIDDLE_FINGER_TIP = 12
        RING_FINGER_MCP = 13
        RING_FINGER_PIP = 14
        RING_FINGER_DIP = 15
        RING_FINGER_TIP = 16
        PINKY_MCP = 17
        PINKY_PIP = 18
        PINKY_DIP = 19
        PINKY_TIP = 20
    """
    global mpDraw
    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert input image to RGB
    results = handDetector.process(imgRGB) #run the image through the mediapipe detector

    if results.multi_hand_landmarks is not None:
        if visualize:
            mpDraw.draw_landmarks(frame,results.multi_hand_landmarks[0],mpHands.HAND_CONNECTIONS) #draw the hand connections onto the frame. NOTE: comment this out if it is unwanted
        return results.multi_hand_landmarks[0].landmark
    else:
        return None

def ptDist(x1, y1, x2, y2):
    """Calculates the distance between points P1 and P2

    Args:
        x1:  P1 X
        y1:  P1 Y
        x2:  P2 X
        y2:  P2 Y

    Returns:
        The distance (as float)
    """
    return(sqrt(pow(x2 - x1, 2) + pow(y2 - y1, 2)))

def fingersClosed(frame, landmarks, visualize = False):
    """Determines if the fingers are closed in an image using its corresponding mediapipe hand landmarks

    Args:
        frame: The image to check
        landmarks: The hand landmarks generated by mediapipe
        visualize (bool, optional): If set to True, this function draws points/lines to understand whats happening. Defaults to False.

    Returns:
        True if fingers are closed, False otherwise
    """
    h, w = frame.shape[:2]
    mcpDist = ptDist(int(landmarks[5].x * w), int(landmarks[5].y * h), int(landmarks[17].x * w), int(landmarks[17].y * h))
    tipDist = ptDist(int(landmarks[8].x * w), int(landmarks[8].y * h), int(landmarks[20].x * w), int(landmarks[20].y * h))
    threshold = mcpDist/3 #threshold in px to be able to control the detection 
    if visualize:
        if tipDist > mcpDist+threshold:
            cv2.line(frame,(int(landmarks[5].x * w), int(landmarks[5].y * h)), (int(landmarks[17].x * w), int(landmarks[17].y * h)), (0,0,255), 2)
            cv2.line(frame,(int(landmarks[8].x * w), int(landmarks[8].y * h)), (int(landmarks[20].x * w), int(landmarks[20].y * h)), (0,255,0), 2)
        else:
            cv2.line(frame,(int(landmarks[5].x * w), int(landmarks[5].y * h)), (int(landmarks[17].x * w), int(landmarks[17].y * h)), (0,255,0), 2)
            cv2.line(frame,(int(landmarks[8].x * w), int(landmarks[8].y * h)), (int(landmarks[20].x * w), int(landmarks[20].y * h)), (0,0,255), 2)
        cv2.circle(frame, (int(landmarks[5].x * w), int(landmarks[5].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[17].x * w), int(landmarks[17].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[8].x * w), int(landmarks[8].y * h)), 2,(255,255,255),4)
        cv2.circle(frame, (int(landmarks[20].x * w), int(landmarks[20].y * h)), 2,(255,255,255),4)
    return not tipDist > mcpDist+threshold

mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
if __name__ == "__main__":
    cam = cv2.VideoCapture(0) #set default video input as camera
    #initialize the detector in video mode, with a maximum of one hand
    handDetector =  mpHands.Hands(static_image_mode=True,
                          max_num_hands=1,
                          min_detection_confidence=0.5,
                          min_tracking_confidence=0.5)
    
    #variables for fps calculation
    pTime = 0
    cTime = 0
    
    while(True):
        (grabbed, frame) = cam.read() #get live image from camera
        frame = cv2.flip(frame, 1) #flip the image to get mirrored view
        h, w, c = frame.shape
        landmarks = findHand(frame, handDetector) #let mediapipe detect the hand
        
        if landmarks is not None:
            wrist = landmarks[0] #grab wrist position for placing text there 
            cv2.putText(frame,str(fingersClosed(frame,landmarks)), (int(wrist.x*w),int(wrist.y*h)), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255), 3) #check if fingers are closed and write the result onto the wrist
        
        #calculate fps
        cTime = time.time()
        fps = 1/(cTime-pTime)
        pTime = cTime
        cv2.putText(frame,str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255), 3) #print fps on frame

        cv2.imshow("Video", frame) #display live feed
        #input()
        #exit()
        input = cv2.waitKey(1) & 0xFF #quit the program with q
        if input == ord("q"):
            break

    cam.release()
    cv2.destroyAllWindows()